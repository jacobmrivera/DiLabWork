{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis on transformed data\n",
    "\n",
    "## Splitting data by experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import balanced_accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../../data/raw_post_multi_extract/transformed/objectLevel/labelingInstanceGazeInfo_jun19.csv')\n",
    "\n",
    "# /Users/jacobrivera/Documents/GitHub/DiLabWork/data/raw_post_multi_extract/transformed/objectLevel/labelingInstanceGazeInfo_jun19.csv\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_185 = df[df['expID'] == 185]\n",
    "df_186 = df[df['expID'] == 186]\n",
    "df_187 = df[df['expID'] == 187]\n",
    "df_188 = df[df['expID'] == 188]\n",
    "\n",
    "df_185_pre = df_185[df_185['pretrained'] == 1]\n",
    "df_185_not = df_185[df_185['pretrained'] == 0]\n",
    "\n",
    "df_186_pre = df_186[df_186['pretrained'] == 1]\n",
    "df_186_not = df_186[df_186['pretrained'] == 0]\n",
    "\n",
    "df_187_pre = df_187[df_187['pretrained'] == 1]\n",
    "df_187_not = df_187[df_187['pretrained'] == 0]\n",
    "\n",
    "df_188_pre = df_188[df_188['pretrained'] == 1]\n",
    "df_188_not = df_188[df_188['pretrained'] == 0]\n",
    "\n",
    "proportion_cols = ['i1_curr_targetProp', 'i2_curr_targetProp', 'i3_curr_targetProp',\n",
    "                    'i4_curr_targetProp', 'i5_curr_targetProp', 'i6_curr_targetProp']\n",
    "\n",
    "all_dfs = [df_185_pre, df_185_not, \n",
    "            df_186_pre, df_186_not,\n",
    "            df_187_pre, df_187_not, \n",
    "            df_188_pre, df_188_not,\n",
    "            df_185, df_186, df_187, df_188]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Index(['subID', 'expID', 'object', 'learned', 'pretrained',\\n       'i1_curr_targetObj', 'i1_curr_targetProp', 'i1_curr_distObj_1',\\n       'i1_curr_distProp_1', 'i1_curr_distObj_2', 'i1_curr_distProp_2',\\n       'i1_curr_distObj_3', 'i1_curr_distProp_3', 'i1_prev_target',\\n       'i1_prev_dist_1', 'i1_prev_dist_2', 'i1_prev_dist_3',\\n       'i2_curr_targetObj', 'i2_curr_targetProp', 'i2_curr_distObj_1',\\n       'i2_curr_distProp_1', 'i2_curr_distObj_2', 'i2_curr_distProp_2',\\n       'i2_curr_distObj_3', 'i2_curr_distProp_3', 'i2_prev_target',\\n       'i2_prev_dist_1', 'i2_prev_dist_2', 'i2_prev_dist_3',\\n       'i3_curr_targetObj', 'i3_curr_targetProp', 'i3_curr_distObj_1',\\n       'i3_curr_distProp_1', 'i3_curr_distObj_2', 'i3_curr_distProp_2',\\n       'i3_curr_distObj_3', 'i3_curr_distProp_3', 'i3_prev_target',\\n       'i3_prev_dist_1', 'i3_prev_dist_2', 'i3_prev_dist_3',\\n       'i4_curr_targetObj', 'i4_curr_targetProp', 'i4_curr_distObj_1',\\n       'i4_curr_distProp_1', 'i4_curr_distObj_2', 'i4_curr_distProp_2',\\n       'i4_curr_distObj_3', 'i4_curr_distProp_3', 'i4_prev_target',\\n       'i4_prev_dist_1', 'i4_prev_dist_2', 'i4_prev_dist_3',\\n       'i5_curr_targetObj', 'i5_curr_targetProp', 'i5_curr_distObj_1',\\n       'i5_curr_distProp_1', 'i5_curr_distObj_2', 'i5_curr_distProp_2',\\n       'i5_curr_distObj_3', 'i5_curr_distProp_3', 'i5_prev_target',\\n       'i5_prev_dist_1', 'i5_prev_dist_2', 'i5_prev_dist_3',\\n       'i6_curr_targetObj', 'i6_curr_targetProp', 'i6_curr_distObj_1',\\n       'i6_curr_distProp_1', 'i6_curr_distObj_2', 'i6_curr_distProp_2',\\n       'i6_curr_distObj_3', 'i6_curr_distProp_3', 'i6_prev_target',\\n       'i6_prev_dist_1', 'i6_prev_dist_2', 'i6_prev_dist_3'],\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Index(['subID', 'expID', 'object', 'learned', 'pretrained',\n",
    "       'i1_curr_targetObj', 'i1_curr_targetProp', 'i1_curr_distObj_1',\n",
    "       'i1_curr_distProp_1', 'i1_curr_distObj_2', 'i1_curr_distProp_2',\n",
    "       'i1_curr_distObj_3', 'i1_curr_distProp_3', 'i1_prev_target',\n",
    "       'i1_prev_dist_1', 'i1_prev_dist_2', 'i1_prev_dist_3',\n",
    "       'i2_curr_targetObj', 'i2_curr_targetProp', 'i2_curr_distObj_1',\n",
    "       'i2_curr_distProp_1', 'i2_curr_distObj_2', 'i2_curr_distProp_2',\n",
    "       'i2_curr_distObj_3', 'i2_curr_distProp_3', 'i2_prev_target',\n",
    "       'i2_prev_dist_1', 'i2_prev_dist_2', 'i2_prev_dist_3',\n",
    "       'i3_curr_targetObj', 'i3_curr_targetProp', 'i3_curr_distObj_1',\n",
    "       'i3_curr_distProp_1', 'i3_curr_distObj_2', 'i3_curr_distProp_2',\n",
    "       'i3_curr_distObj_3', 'i3_curr_distProp_3', 'i3_prev_target',\n",
    "       'i3_prev_dist_1', 'i3_prev_dist_2', 'i3_prev_dist_3',\n",
    "       'i4_curr_targetObj', 'i4_curr_targetProp', 'i4_curr_distObj_1',\n",
    "       'i4_curr_distProp_1', 'i4_curr_distObj_2', 'i4_curr_distProp_2',\n",
    "       'i4_curr_distObj_3', 'i4_curr_distProp_3', 'i4_prev_target',\n",
    "       'i4_prev_dist_1', 'i4_prev_dist_2', 'i4_prev_dist_3',\n",
    "       'i5_curr_targetObj', 'i5_curr_targetProp', 'i5_curr_distObj_1',\n",
    "       'i5_curr_distProp_1', 'i5_curr_distObj_2', 'i5_curr_distProp_2',\n",
    "       'i5_curr_distObj_3', 'i5_curr_distProp_3', 'i5_prev_target',\n",
    "       'i5_prev_dist_1', 'i5_prev_dist_2', 'i5_prev_dist_3',\n",
    "       'i6_curr_targetObj', 'i6_curr_targetProp', 'i6_curr_distObj_1',\n",
    "       'i6_curr_distProp_1', 'i6_curr_distObj_2', 'i6_curr_distProp_2',\n",
    "       'i6_curr_distObj_3', 'i6_curr_distProp_3', 'i6_prev_target',\n",
    "       'i6_prev_dist_1', 'i6_prev_dist_2', 'i6_prev_dist_3'],'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_object_subject_target(df, object, experiment, subject, learner_type):\n",
    "    object_groups = df.groupby('object')\n",
    "    target_columns = ['subID', 'expID', 'object', 'learned', 'pretrained',\n",
    "                  'i1_curr_targetProp', 'i2_curr_targetProp', 'i3_curr_targetProp',\n",
    "                  'i4_curr_targetProp', 'i5_curr_targetProp', 'i6_curr_targetProp']\n",
    "    target_df_obj = object_groups.get_group(object)[target_columns]\n",
    "\n",
    "    target_df_obj_exp = target_df_obj[(target_df_obj['expID'] == experiment) & (target_df_obj['subID'] == subject)]\n",
    "\n",
    "    proportion_cols = ['i1_curr_targetProp', 'i2_curr_targetProp', 'i3_curr_targetProp',\n",
    "                  'i4_curr_targetProp', 'i5_curr_targetProp', 'i6_curr_targetProp']\n",
    "\n",
    "    domain = np.array([1, 2, 3, 4, 5, 6]).reshape(-1,1)\n",
    "    plt.scatter(domain, target_df_obj_exp[proportion_cols], label=subject)\n",
    "\n",
    "    X = np.array(target_df_obj_exp[proportion_cols].values.flatten().tolist()).reshape(-1, 1)\n",
    "\n",
    "    reg = LinearRegression().fit(domain, X)\n",
    "\n",
    "    y_pred = [reg.predict([[i]]) for i in range(1,7)]\n",
    "    flatten_y_pred = [j for sub in y_pred for j in sub]\n",
    "\n",
    "    plt.plot(domain, flatten_y_pred, label='regression')\n",
    "    plt.xlabel('instance')\n",
    "    plt.ylabel('gaze proportion')\n",
    "    plt.title('{level} learners: target obj {obj} gaze prop per labeling instances'.format(level=learner_type,obj=object))\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def grapher(df, obj):\n",
    "    proportion_cols = ['i1_curr_targetProp', 'i2_curr_targetProp', 'i3_curr_targetProp',\n",
    "                    'i4_curr_targetProp', 'i5_curr_targetProp', 'i6_curr_targetProp']\n",
    "    domain = np.array([1, 2, 3, 4, 5, 6]).reshape(-1,1)\n",
    "\n",
    "    for sub in df['subID'].unique():\n",
    "        print(\"~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\")\n",
    "        plt.scatter(domain, df[(df['object'] == obj) & (df['subID'] == sub)][proportion_cols])\n",
    "        plt.show()\n",
    "\n",
    "        if (df[(df['object'] == obj) & (df['subID'] == sub)]['learned'].values == 1):\n",
    "            print(\"LEARNED\")\n",
    "        else:\n",
    "            print(\"NOT LEARNED\")\n",
    "        print(\"~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\")\n",
    "\n",
    "# grapher(df_188_not, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "prop_cols = [\n",
    "        'i1_curr_targetProp', 'i1_curr_distProp_1',  'i1_curr_distProp_2' ,'i1_curr_distProp_3',\n",
    "        'i1_prev_target', 'i1_prev_dist_1', 'i1_prev_dist_2', 'i1_prev_dist_3',\n",
    "        'i2_curr_targetProp', 'i2_curr_distProp_1', 'i2_curr_distProp_2', 'i2_curr_distProp_3',\n",
    "        'i2_prev_target', 'i2_prev_dist_1', 'i2_prev_dist_2', 'i2_prev_dist_3',\n",
    "        'i3_curr_targetProp', 'i3_curr_distProp_1',  'i3_curr_distProp_2', 'i3_curr_distProp_3',\n",
    "        'i3_prev_target', 'i3_prev_dist_1', 'i3_prev_dist_2', 'i3_prev_dist_3',\n",
    "        'i4_curr_targetProp', 'i4_curr_distProp_1',  'i4_curr_distProp_2',\n",
    "        'i4_curr_distProp_3', 'i4_prev_target', 'i4_prev_dist_1', 'i4_prev_dist_2', 'i4_prev_dist_3',\n",
    "        'i5_curr_targetProp', 'i5_curr_distProp_1', 'i5_curr_distProp_2','i5_curr_distProp_3',\n",
    "        'i5_prev_target', 'i5_prev_dist_1', 'i5_prev_dist_2', 'i5_prev_dist_3',\n",
    "        'i6_curr_targetProp','i6_curr_distProp_1',  'i6_curr_distProp_2', 'i6_curr_distProp_3',\n",
    "        'i6_prev_target','i6_prev_dist_1', 'i6_prev_dist_2', 'i6_prev_dist_3']\n",
    "\n",
    "distractor_cols  = [\n",
    "        'i1_curr_targetProp', 'i1_curr_distProp_1', 'i1_curr_distProp_2', 'i1_curr_distProp_3',\n",
    "        'i2_curr_targetProp', 'i2_curr_distProp_1', 'i2_curr_distProp_2', 'i2_curr_distProp_3',\n",
    "        'i3_curr_targetProp', 'i3_curr_distProp_1', 'i3_curr_distProp_2', 'i3_curr_distProp_3',\n",
    "        'i4_curr_targetProp', 'i4_curr_distProp_1', 'i4_curr_distProp_2', 'i4_curr_distProp_3',\n",
    "        'i5_curr_targetProp', 'i5_curr_distProp_1', 'i5_curr_distProp_2', 'i5_curr_distProp_3',\n",
    "        'i6_curr_targetProp', 'i6_curr_distProp_1', 'i6_curr_distProp_2', 'i6_curr_distProp_3',]\n",
    "\n",
    "distractor_cols_w_pre  = [ 'pretrained',\n",
    "        'i1_curr_targetProp', 'i1_curr_distProp_1', 'i1_curr_distProp_2', 'i1_curr_distProp_3',\n",
    "        'i2_curr_targetProp', 'i2_curr_distProp_1', 'i2_curr_distProp_2', 'i2_curr_distProp_3',\n",
    "        'i3_curr_targetProp', 'i3_curr_distProp_1', 'i3_curr_distProp_2', 'i3_curr_distProp_3',\n",
    "        'i4_curr_targetProp', 'i4_curr_distProp_1', 'i4_curr_distProp_2', 'i4_curr_distProp_3',\n",
    "        'i5_curr_targetProp', 'i5_curr_distProp_1', 'i5_curr_distProp_2', 'i5_curr_distProp_3',\n",
    "        'i6_curr_targetProp', 'i6_curr_distProp_1', 'i6_curr_distProp_2', 'i6_curr_distProp_3',]\n",
    "\n",
    "curr_prop_cols = ['i1_curr_targetProp', 'i2_curr_targetProp', 'i3_curr_targetProp',\n",
    "                    'i4_curr_targetProp', 'i5_curr_targetProp', 'i6_curr_targetProp']\n",
    "\n",
    "curr_prop_cols_w_pre = ['pretrained',\n",
    "                        'i1_curr_targetProp', 'i2_curr_targetProp', 'i3_curr_targetProp',\n",
    "                        'i4_curr_targetProp', 'i5_curr_targetProp', 'i6_curr_targetProp']\n",
    "\n",
    "all_dfs = [df_185_pre, df_185_not, \n",
    "            df_186_pre, df_186_not,\n",
    "            df_187_pre, df_187_not, \n",
    "            df_188_pre, df_188_not,\n",
    "            df_185, df_186, df_187, df_188]\n",
    "all_dfs_strings = ['df_185_pre', 'df_185_not', \n",
    "            'df_186_pre', 'df_186_not',\n",
    "            'df_187_pre', 'df_187_not', \n",
    "            'df_188_pre', 'df_188_not',\n",
    "            'df_185', 'df_186', 'df_187', 'df_188']\n",
    "\n",
    "col_array = [curr_prop_cols,curr_prop_cols_w_pre, distractor_cols, distractor_cols_w_pre]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data subset: df_186\n",
      "Columns used are the proportions of current target\n",
      "Kernel: rbf\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      1.00      0.92       187\n",
      "           1       0.00      0.00      0.00        33\n",
      "\n",
      "    accuracy                           0.85       220\n",
      "   macro avg       0.42      0.50      0.46       220\n",
      "weighted avg       0.72      0.85      0.78       220\n",
      "\n",
      "\n",
      "\n",
      "Data subset: df_186\n",
      "Columns used are the proportions of current target including pretrained col\n",
      "Kernel: rbf\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       187\n",
      "           1       1.00      1.00      1.00        33\n",
      "\n",
      "    accuracy                           1.00       220\n",
      "   macro avg       1.00      1.00      1.00       220\n",
      "weighted avg       1.00      1.00      1.00       220\n",
      "\n",
      "\n",
      "\n",
      "Data subset: df_186\n",
      "Columns used are the proportions of current target and distractors\n",
      "Kernel: rbf\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      1.00      0.92       187\n",
      "           1       0.00      0.00      0.00        33\n",
      "\n",
      "    accuracy                           0.85       220\n",
      "   macro avg       0.42      0.50      0.46       220\n",
      "weighted avg       0.72      0.85      0.78       220\n",
      "\n",
      "\n",
      "\n",
      "Data subset: df_186\n",
      "Columns used are the proportions of current target and distractors including pretrained col\n",
      "Kernel: rbf\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       187\n",
      "           1       1.00      1.00      1.00        33\n",
      "\n",
      "    accuracy                           1.00       220\n",
      "   macro avg       1.00      1.00      1.00       220\n",
      "weighted avg       1.00      1.00      1.00       220\n",
      "\n",
      "\n",
      "\n",
      "Data subset: df_187\n",
      "Columns used are the proportions of current target\n",
      "Kernel: rbf\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.97      0.81       149\n",
      "           1       0.60      0.08      0.15        71\n",
      "\n",
      "    accuracy                           0.69       220\n",
      "   macro avg       0.65      0.53      0.48       220\n",
      "weighted avg       0.66      0.69      0.59       220\n",
      "\n",
      "\n",
      "\n",
      "Data subset: df_187\n",
      "Columns used are the proportions of current target including pretrained col\n",
      "Kernel: rbf\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       149\n",
      "           1       1.00      1.00      1.00        71\n",
      "\n",
      "    accuracy                           1.00       220\n",
      "   macro avg       1.00      1.00      1.00       220\n",
      "weighted avg       1.00      1.00      1.00       220\n",
      "\n",
      "\n",
      "\n",
      "Data subset: df_187\n",
      "Columns used are the proportions of current target and distractors\n",
      "Kernel: rbf\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.96      0.81       149\n",
      "           1       0.57      0.11      0.19        71\n",
      "\n",
      "    accuracy                           0.69       220\n",
      "   macro avg       0.63      0.54      0.50       220\n",
      "weighted avg       0.65      0.69      0.61       220\n",
      "\n",
      "\n",
      "\n",
      "Data subset: df_187\n",
      "Columns used are the proportions of current target and distractors including pretrained col\n",
      "Kernel: rbf\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       149\n",
      "           1       1.00      1.00      1.00        71\n",
      "\n",
      "    accuracy                           1.00       220\n",
      "   macro avg       1.00      1.00      1.00       220\n",
      "weighted avg       1.00      1.00      1.00       220\n",
      "\n",
      "\n",
      "\n",
      "Data subset: df_188\n",
      "Columns used are the proportions of current target\n",
      "Kernel: rbf\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.63      0.66       115\n",
      "           1       0.61      0.66      0.64       101\n",
      "\n",
      "    accuracy                           0.65       216\n",
      "   macro avg       0.65      0.65      0.65       216\n",
      "weighted avg       0.65      0.65      0.65       216\n",
      "\n",
      "\n",
      "\n",
      "Data subset: df_188\n",
      "Columns used are the proportions of current target including pretrained col\n",
      "Kernel: rbf\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       115\n",
      "           1       1.00      1.00      1.00       101\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      1.00      1.00       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "\n",
      "\n",
      "Data subset: df_188\n",
      "Columns used are the proportions of current target and distractors\n",
      "Kernel: rbf\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.65      0.66       115\n",
      "           1       0.61      0.62      0.62       101\n",
      "\n",
      "    accuracy                           0.64       216\n",
      "   macro avg       0.64      0.64      0.64       216\n",
      "weighted avg       0.64      0.64      0.64       216\n",
      "\n",
      "\n",
      "\n",
      "Data subset: df_188\n",
      "Columns used are the proportions of current target and distractors including pretrained col\n",
      "Kernel: rbf\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       115\n",
      "           1       1.00      1.00      1.00       101\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      1.00      1.00       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jacob\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\jacob\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\jacob\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\jacob\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\jacob\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\jacob\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "data = all_dfs[1] # df_185_not\n",
    "\n",
    "col_array_names = [\"proportions of current target\", \"proportions of current target including pretrained col\", \n",
    "                   \"proportions of current target and distractors\", \"proportions of current target and distractors including pretrained col\"]\n",
    "# kernels = ['linear','rbf','sigmoid','poly']\n",
    "kernels = ['rbf']\n",
    "\n",
    "\n",
    "for i in range(len(all_dfs)):\n",
    "    for j in range(len(col_array)):\n",
    "        x = all_dfs[i][col_array[j]]\n",
    "        y = all_dfs[i]['pretrained']\n",
    "\n",
    "        if len(x) == 0: continue\n",
    "        if len(y.unique()) == 1: continue\n",
    "        X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "\n",
    "        for kern in kernels:\n",
    "            clf = svm.SVC(kernel=kern)\n",
    "            clf.fit(X_train, y_train)\n",
    "            y_pred = clf.predict(X_test)\n",
    "            print()\n",
    "            print('Data subset: {sub}\\nColumns used are the {cols}\\nKernel: {kernel}'.format(sub=all_dfs_strings[i],cols=col_array_names[j], kernel=kern))\n",
    "            print(classification_report(y_pred=y_pred, y_true=y_test))\n",
    "            # print( \"Accuracy: \", balanced_accuracy_score(y_test, y_pred))\n",
    "            print()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.97      0.89       173\n",
      "           1       0.69      0.23      0.35        47\n",
      "\n",
      "    accuracy                           0.81       220\n",
      "   macro avg       0.76      0.60      0.62       220\n",
      "weighted avg       0.79      0.81      0.78       220\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df_train = df_185\n",
    "\n",
    "X = df_train[distractor_cols]\n",
    "y = df_train['learned']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "clf = svm.SVC(kernel=\"rbf\")\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "print(classification_report(y_pred=y_pred, y_true=y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: Experiment 186, not trained rows, distractor columns included in training\n",
      "\t pretrained column NOT included in training\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.35      0.46        54\n",
      "           1       0.82      0.94      0.87       166\n",
      "\n",
      "    accuracy                           0.80       220\n",
      "   macro avg       0.74      0.65      0.67       220\n",
      "weighted avg       0.78      0.80      0.77       220\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "x_str = 'Experiment 186, not trained rows, distractor columns included in training\\n\\t pretrained column NOT included in training'\n",
    "x = df_187[curr_prop_cols_w_pre]\n",
    "y = df_187['learned']\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "\n",
    "clf = LogisticRegression()\n",
    "clf = clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "\n",
    "print('Dataset: {data}'.format(data=x_str))\n",
    "print(classification_report(y_pred=y_pred, y_true=y_test))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.42      0.17      0.24        30\n",
      "           1       0.88      0.96      0.92       186\n",
      "\n",
      "    accuracy                           0.85       216\n",
      "   macro avg       0.65      0.56      0.58       216\n",
      "weighted avg       0.81      0.85      0.82       216\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df_188[curr_prop_cols_w_pre], df_188['learned'], test_size=0.2, random_state=42)\n",
    "y_pred = clf.predict(X_test)\n",
    "print(classification_report(y_pred=y_pred, y_true=y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.72      0.71       334\n",
      "           1       0.82      0.81      0.82       541\n",
      "\n",
      "    accuracy                           0.78       875\n",
      "   macro avg       0.76      0.76      0.76       875\n",
      "weighted avg       0.78      0.78      0.78       875\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "x = df[curr_prop_cols_w_pre]\n",
    "y = df['learned']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "\n",
    "clfa = AdaBoostClassifier(n_estimators=100, random_state=0)\n",
    "clfa.fit(X_train, y_train)\n",
    "y_pred = clfa.predict(X_test)\n",
    "print(classification_report(y_pred=y_pred, y_true=y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.56      0.52       145\n",
      "           1       0.93      0.91      0.92       935\n",
      "\n",
      "    accuracy                           0.86      1080\n",
      "   macro avg       0.71      0.73      0.72      1080\n",
      "weighted avg       0.87      0.86      0.86      1080\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = clfa.predict(df_188[curr_prop_cols_w_pre])\n",
    "print(classification_report(y_pred=y_pred, y_true=df_188['learned']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.03, 0.1 , 0.22, 0.13, 0.25, 0.16, 0.11])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clfa.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
